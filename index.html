<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="description" content="Mimansa Jaiswal Academic Page" />
    <link rel="stylesheet" href="css/main.css" />
    <link rel="icon" href="img/umlogo.png">
    <title>Mimansa Jaiswal</title>
  </head>
  <body>
    <header>
      <div class="container header-inner">
        <h1 class="name">
          Mimansa Jaiswal
        </h1>
        <nav>
          <ul>
            <li><a href="#publications">Publications</a></li>
            <li><a href="#experience">Experience</a></li>
            <li><a href="#suggestedlinks">Good Advice</a></li>
            <li><a href="https://drive.google.com/file/d/114a9vX3dpjajZa9isMDg_d294-v-FcZ7/view?usp=sharing&authuser=0" target="_blank">CV</a></li>
            <li><a href="blog.html" target="_blank">Miscellaneous</a></li>
          </ul>
        </nav>
      </div>
    </header>
    <main>
      <section id="about" class="py-1">
        <div class="container about-inner">
          <div class="about-desc">
            <p class="pb-1">
              I'm Mimansa, a third year <strong>PhD candidate</strong> in Computer Science (AI/Interactive Systems) at the <strong><a href="https://umich.edu/">University of Michigan</strong></a>. I am fortunate to be working with
              <a href="http://web.eecs.umich.edu/~emilykmp/" class="bold ">Prof. Emily Provost</a> as part of the
              <a href="http://web.eecs.umich.edu/~emilykmp/chai/index.html" > CHAI group</a>. I completed my undergrad in Computer Engineering from
              <a href="http://ietdavv.edu.in/" > Institute of Engineering and Technology, Indore</a>
              in 2017, and worked with<a href="https://scholar.google.co.in/citations?user=lMpy-xQAAAAJ" class="bold "> Prof. G.L. Prajapati</a>
              for my bachelor's thesis.
            </p>
            <div class="contact-info">
              <a href="mailto:mimansa@umich.edu">mimansa@umich.edu</a>
              <!-- <span>||</span>
              <a href="mailto:mimansa.jaiswal@gmail.com"
                >mimansa.jaiswal@gmail.com</a
              > -->
              <span>||</span>
              <a href="https://www.linkedin.com/in/mimansajaiswal">LinkedIn</a>
              <span>||</span>
              <a href="https://twitter.com/MimansaJ">Twitter</a>
              <span>||</span>
              <a href="https://scholar.google.com/citations?user=05FDs5kAAAAJ"
                >Google Scholar</a
              >
              <span>||</span>
              <a
                href="https://drive.google.com/file/d/114a9vX3dpjajZa9isMDg_d294-v-FcZ7/view?usp=sharing&authuser=0" target="_blank"
                >CV</a
              >
            </div>
            <div class="research">
              <h1 class="heading-m">
                Research interests
              </h1>
              <p class="pb-1">
                My present research interests lie in the topics that fall under
                the umbrella of
                <span class="bold"
                  >Robust and Interpretable Human Centered
                  Computing</span
                >. I work in the area of robust and interpretable systems for social signal
                processing using
                <span class="bold">natural language understanding and speech processing</span>
                to the various problems, such as, conversation and discourse analysis, emotion modelling etc. I am primarily interested in
                understanding what causes the state-of-the-art machine learning models to fail <span class="bold">[<a href="https://slideslive.com/38928670/noisebased-augmentation-techniques-for-emotion-datasets-what-do-we-recommend">Failure Analysis of ML models</a>]</span> or
                perform differently than expected <span class="bold">[<a href="https://arxiv.org/pdf/1908.08979.pdf">Evaluation of ML models</a>]</span>, how these failure points can be used by an expert <span class="bold">[<a href="https://arxiv.org/pdf/1903.11672.pdf">Model Testing and Debugging</a>]</span> and predictions be explained to a general audience <span class="bold">[Model Explanation]</span> ,
                how can we train or tune these models such that do not learn about certain variables <span class="bold">[<a href="https://arxiv.org/pdf/1908.08979.pdf">Robust</a> and <a href="https://arxiv.org/pdf/1910.13212.pdf">Private</a> ML models]</span>, and how these models can benefit from known human knowledge <span class="bold">[<a href="https://arxiv.org/pdf/1910.05115.pdf">Expert Informed Machine Learning</a> or Human-in-the-Loop ML]</span>.
              </p>
              <p>
                In the past, I have also worked in Machine Learning for Health, especially, in relation to mental health.
                I have worked on mental health prediction using social
                media posts as proxy (B.E. Thesis). I have also worked on
                <a href="https://arxiv.org/pdf/1903.05210.pdf">multimodal deception detection</a> and <a href="https://arxiv.org/pdf/1903.04484.pdf">predicting
                  empathy in human behavior</a>.
              </p>
            </div>
          </div>
          <img src="img/Mimansa.jpg" alt="Mimanas" />
        </div>
      </section>
      <section id="updates" class="py-1">
        <div class="container updates-inner">
          <h1 class="heading-m">
            Updates
          </h1>
          <ul>
            <li>[July 2020] <span style="color:red;font-weight: bold;">[New!]</span> I'll be attending ACL 2020 online. See you there!</li>
            <li>[May 2020] <span style="color:red;font-weight: bold;">[New!]</span> Excited to be interning in the Conversation AI group at Facebook AI working on automated dialogue evaluation.</li>
            <li>[Feb 2020] <span style="color:red;font-weight: bold;">[New!]</span> Our paper on datatset created collecting multimodal data for emotion recognition under varying circumstances has been accepted to LREC 2020.</li>
            <li>[Dec 2019] <span style="color:red;font-weight: bold;">[New!]</span> I'll be attending NeuRIPS. Shoot me an email if you want to meet and talk about anything!</li>
          </ul>
        </div>
      </section>
      <section id="publications" class="py-1">
        <div class="container publications-inner">
          <h1 class="heading-m"> Publications</h1>
          <div class="submitted">
            <h2 class="heading-s ml-1">Submitted papers</h2>
            <ul>
              <li>
                <div class="collapsible">
                  <p><span class="bold"> An Interpretation Framework for Explaining Models Trained for Computational Paralinguistic Tasks</span></p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p><span class="bold">Mimansa Jaiswal</span>, Emily Mower Provost
                  <!--<br>Interspeech 2020<br>-->
                    <!--<a href="https://arxiv.org/pdf/1910.13212.pdf">Paper</a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>Speech signals in particular are highly time varying and attention
                  mechanisms that are generally used for interpretation might pick up discontinuous regions that are not human interpretable.
                  In this paper, we propose a framework to attend to interpretation of speech signals for paralinguistic tasks.
                  We then use this framework to generate textual explanations for the model prediction.
                </p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p><span class="bold"> When and Why Should You Trust a Model is Private? Evaluating Shifts in Explanation of Privacy-Preserving NLP Models </span></p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p><span class="bold">Mimansa Jaiswal</span>, Emily Mower Provost
                  <!--<br>Interspeech 2020<br>-->
                    <!--<a href="https://arxiv.org/pdf/1910.13212.pdf">Paper</a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>We believe that understanding shifts in the interpretation of privacy preserving models can help us understand how
                  models unlearn  chosen factors as compared to when not trained to preserve privacy, and if this focus  aligns  with  what  humans
                  consider  important  to  learn those factors. This will help us inform better privacy modelling techniques such that the
                  resultant models are trusted by humans.
                </p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p><span class="bold"> Noise Based Augmentation of Emotion Datasets: What's ideal and What Isn't? </span></p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p><span class="bold">Mimansa Jaiswal</span>, Emily Mower Provost
                  <br>Interspeech 2020<br>
                    <!--<a href="https://arxiv.org/pdf/1910.13212.pdf">Paper</a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>Multiple noise-based data augmentation approaches have been proposed to counteract this challenge in other speech domains.
                  But, unlike speech recognition and speaker verification, the underlying label of emotion data may change given the addition of noise.
                  In this work, we propose a set of recommendations for noise-based augmentation of emotion datasets based on human and machine performance evaluation of
                  generated realistic noisy samples using multiple categories of environmental and synthetic noise.</p> </div>
              </li>

            </ul>
          </div>

          <div class="accepted">
            <h2 class="heading-s ml-1">Accepted Publications</h2>
            <ul>
              <li>
                <div class="collapsible">
                  <p><span class="bold"> Noise-Based Augmentation Techniques for Emotion Datasets: What do we Recommend? </span></p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p><span class="bold">Mimansa Jaiswal</span>, Emily Mower Provost
                  <br>Association for Computational Linguistics, Student Research Workshop (ACL-SRW) 2020<br>
                   <a href="https://slideslive.com/38928670/noisebased-augmentation-techniques-for-emotion-datasets-what-do-we-recommend">Presentation</a>
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>Multiple noise-based data augmentation approaches have been proposed to counteract this challenge in other speech domains.
                  But, unlike speech recognition and speaker verification, the underlying label of emotion data may change given the addition of noise.
                  In this work, we propose a set of recommendations for noise-based augmentation of emotion datasets based on human and machine performance evaluation of
                  generated realistic noisy samples using multiple categories of environmental and synthetic noise.</p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p><span class="bold"> MuSE: Multimodal Stressed Emotion Dataset </span></p>
                    <button class="collapsible-btn">[TLDR]</button>
                  <p><span class="bold">Mimansa Jaiswal</span>, Cristian-Paul Bara, Yuanhang Luo, Rada Mihalcea, Mihai Burzo, Emily Mower Provost
                    <br>Conference on Language Resources and Evaluation (LREC) 2020<br>
                    <a href="http://www.lrec-conf.org/proceedings/lrec2020/pdf/2020.lrec-1.187.pdf">Paper</a>
                    <!--<span>||</span><a href="">Dataset</a>-->
                  </p></div>
                <div class="content"><p class="py-025"><span class ="bold">TLDR: </span>. This paper presents a dataset, Multimodal Stressed
                  Emotion (MuSE), to study the multimodal interplay between the presence of stress and expressions of affect. We describe the data
                  collection protocol, the possible areas of use, and the annotations for the emotional content of the recordings. </p></div>
              </li>

              <li>
                <div class="collapsible">
                  <p><span class="bold"> Privacy Enhanced Multimodal Neural Representations for Emotion Recognition </span></p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p><span class="bold">Mimansa Jaiswal</span>, Emily Mower Provost
                  <br>AAAI Conference on Artificial Intelligence (AAAI) 2020<br>
                    <a href="https://arxiv.org/pdf/1910.13212.pdf">Paper</a>
                    <!--<span>||</span><a href=""> Poster </a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>In this work,
                  we show how multimodal representations trained for a primary task, here emotion recognition, can unintentionally leak
                  demographic information, which could override a selected
                  opt-out option by the user. We analyze how this leakage differs in representations obtained from textual, acoustic, and
                  multimodal data. We use an adversarial learning paradigm
                  to unlearn the private information present in a representation.</p> </div>
              </li>

              <li>
                <div >
                  <p>  <span class="bold"> Investigating and Tackling Privacy Concerns in Multimodal Neural Representations for Emotion Recognition </span> </p>
                  <p> <span class="bold">Mimansa Jaiswal</span>, Emily Mower Provost
                    <br>In Human Centered Machine Learning (HCML, NeuRIPS workshop) 2019.
                    <br>In Privacy in Machine Learning (PriML, NeuRIPS workshop) 2019.
                    <br>Abstract presentation at Women in Machine Learning Workshop, co-located with NeurIPS 2019.
                  </p></div>
              </li>

              <li>
                <div class="collapsible">
                  <p> <span class="bold"> Controlling for Confounders in Multimodal Emotion Classification via Adversarial Learning </span> </p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p> <span class="bold">Mimansa Jaiswal</span>, Zakaria Aldeneh, Emily Mower Provost
                    <br> International Conference on Multimodal Interaction (ICMI) 2019.<br>
                    <a href="https://arxiv.org/pdf/1908.08979.pdf">Paper</a>
                    <!--<span>||</span><a href=""> Slides </a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>We study how stress alters acoustic
                  and lexical emotional predictions, paying special attention
                  to how modulations due to stress affect the transferability
                  of learned emotion recognition models across domains</p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p> <span class="bold"> Identifying Mood Episodes Using Dialogue Features from Clinical Interviews </span> </p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p> Zakaria Aldeneh, <span class="bold">Mimansa Jaiswal</span>, Emily Mower Provost
                    <br> Interspeech 2019.<br>
                    <a href="https://arxiv.org/pdf/1910.05115.pdf">Paper</a>
                    <!--<span>||</span><a href=""> Poster </a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span> Mental health professionals assess symptom severity
                  through semi-structured clinical interviews. During these interviews, they observe their patients’ spoken behaviors, including
                  both what the patients say and how they say it. In this work,
                  we move beyond acoustic and lexical information, investigating
                  how higher-level interactive patterns also change during mood
                  episodes.</p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p> <span class="bold"> MuSE-ing on the Impact of Utterance Ordering on Crowdsourced Emotion Annotations </span> </p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p> <span class="bold">Mimansa Jaiswal</span>, Zakaria Aldeneh, Cristian-Paul Bara, Yuanhang Luo, Mihai Burzo, Rada Mihalcea, Emily Mower Provost
                    <br> International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2019.<br>
                    <a href="https://arxiv.org/pdf/1903.11672.pdf">Paper</a>
                    <!--<span>||</span><a href=""> Poster </a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>Emotion expression and perception are inherently subjective. There is generally not a single annotation that
                  can be unambiguously declared “correct.” As a result, annotations
                  are colored by the manner in which they were collected, i.e., with or without context.</p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p> <span class="bold"> The PRIORI Emotion Dataset: Linking Mood to Emotion Detected In-the-Wild </span> </p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p> Soheil Khorram, <span class="bold">Mimansa Jaiswal</span>, John Gideon, Melvin McInnis, Emily Mower Provost
                    <br> Interspeech 2018.<br>
                    <a href="https://arxiv.org/pdf/1806.10658.pdf">Paper</a>
                    <!--<span>||</span><a href=""> Poster </a>-->
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>This paper presents critical steps in developing
                  this pipeline, including (a) a new in the wild emotion dataset,
                  the PRIORI Emotion Dataset, (b) activation/valence
                  emotion recognition baselines, and, (c) establish emotion as a meta-feature for mood state monitoring. </p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p> <span class="bold"> "Hang in there": Lexical and Visual Analysis to Identify Posts Warranting Empathetic Responses </span> </p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p> <span class="bold">Mimansa Jaiswal</span>, Sairam Tabibu, Erik Cambria
                    <br> Florida Artificial Intelligence Research Society Conference (FLAIRS) 2017.<br>
                    <a href="https://arxiv.org/pdf/1903.05210.pdf">Paper</a>
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>Saying "You deserved it!" to "I failed the test"
                  is not a good idea. In this
                  paper, we propose a method supported by hand-crafted features to judge if the discourse or statement requires an
                  empathetic response. </p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p> <span class="bold"> "The Truth and Nothing But The Truth": Multimodal Analysis for Deception Detection </span> </p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p> <span class="bold">Mimansa Jaiswal</span>, Sairam Tabibu, Rajiv Bajpai
                    <br> International Conference on Data Mining Workshops (ICDMW) 2016.<br>
                    <a href="https://arxiv.org/pdf/1903.04484.pdf">Paper</a>
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>We propose a data-driven method (SVMs) for
                  automatic
                  deception detection in real-life trial data using visual (OpenFace) and verbal
                  cues (Bag of Words). </p> </div>
              </li>

              <li>
                <div class="collapsible">
                  <p> <span class="bold"> Contextual Text-mining Approach for Teacher Feedback </span> </p>
                  <button class="collapsible-btn">[TLDR]</button>
                  <p> <span class="bold">Mimansa Jaiswal</span>, Vinshi Vanvat, Manasi Tiwari
                    <br> Extended Abstracts, Information Systems Research and Teaching 2014.
                  </p></div>
                <div class="content"> <p class="py-025"> <span class ="bold">TLDR: </span>Most teacher review systems use word matching to assign positive and negative scores. But sentiment of words change according to context. Which n-grams are common in reviews, and what sentiment do they show? </p> </div>
              </li>
            </ul>
          </div>
        </div>

      </section>
      <section id="experience" class="py-1">
        <div class="container experience-inner">
          <!--<h1 class="heading-m">
            Experience
          </h1>-->
          <div class="internship">
            <h1 class="heading-m" class="py-1">Experience</h1>

            <ul style=" list-style-type: none;">

              <li>
                <div >
                  <p><img src="img/facebook-research.png" alt="FBAI" style="float:left;width:90px;height:70px;padding-right: 20px;"/>
                    <span class="bold"><a href="https://ai.facebook.com/research/conversational-ai/">ConversationAI</a>, <a href="https://ai.facebook.com/">Facebook AI</a></span> <br>
                    Summer Research Intern, May 2020 - August 2020 <br>
                    Mentor: <a href="https://sites.google.com/view/beirami" >Ahmad Beirami</a><br>
                    Topic: Defining interpretable and generalizable user satisfaction metric informed by human knowledge <br>
                  </p>
              </li>

              <li>
                <div>
                  <p><img src="img/NTU_logo.jpg" alt="NTU, Singapore" style="float:left;width:90px;height:70px;padding-right: 20px;"/><span class="bold"><a href="https://sentic.net/">SENTIC Lab</a>, Nanyang Technological University, Singapore</span> <br>
                    Summer Research Assistant, April 2016 - July 2016 <br>
                    Mentor: <a href="https://sentic.net/erikcambria/" >Prof. Erik Cambria</a><br>
                    Topic: Multimodal detection of human behavior: empathy and deception <br>
                  </p>
              </li>

              <li>
                <div>
                  <p><img src="img/academias.png" alt="Academia Sinica, Taiwan" style="float:left;width:90px;height:70px;padding-right: 20px;"/><span class="bold"><a href="http://academiasinicanlplab.github.io/">NLP and Sentiment Analysis (NLPSA) Lab</a>, Academia Sinica, Taipei, Taiwan</span> <br>
                    Research Intern, December 2015 - February 2016 <br>
                    Mentor: <a href="https://www.iis.sinica.edu.tw/pages/lwku/" >Prof. Lun-Wei Ku</a><br>
                    Topic: Human perception of conversation sentiment visualization in chat interfaces  <br>
                  </p>
              </li>

              <li>
                <div>
                  <p><img src="img/iiitd.jpg" alt="Indraprastha Institute of Information Technology, Delhi" style="float:left;width:90px;height:70px;padding-right: 20px;"/><span class="bold"><a href="https://iiitd.ac.in/" >IIIT Delhi </a>, India</span> <br>
                    Summer Research Assistant, May 2015 - July 2015 <br>
                    Mentor: <a href="https://www.iiitd.edu.in/~praveshb/" >Prof. Pravesh Biyani</a><br>
                    Topic: Finding the optimal routes under user specified user-constraints for last mile cab-pooling <br>
                  </p>
              </li>

              <li>
                <div>
                  <p><img src="img/zootout.jpg" alt="Zootout" style="float:left;width:90px;height:70px;padding-right: 20px;"/><span class="bold">Zootout</span> <br>
                    Technical Intern, January 2015 - April 2015 <br>
                    Mentor: Sumay Dubey</a><br>
                    Topic: Aspect Based Sentiment Analysis of reviews for better hotel and restaurant recommendation <br>
                  </p>
              </li>

            </ul>
          </div>
          <div class="awards">
            <h1 class="heading-m py-1"></h1>
            <h1 class="heading-m" class="py-1">Awards and Recognition</h1>
            <ul>
              <li>Awarded Fellowship for Year-1 of PhD program at University of Michigan [At department level]</li>
              <li>Selected to attend CRA-W '18 and CRA-W '20</li>
              <li>Selected to attend Grace Hopper Celebration '18 [At institute level]</li>
            </ul>
            <div class="service">

              <h1 class="heading-m" class="py-1">Talks</h1>
              <ul>
                <li>

                    PyCon India:
                    <a href="https://youtu.be/A1IKw67vYkE"
                      >Building companion chatbot with python</a
                    >
                    [September 2016]

                </li>
                <li>

                    PyCon Singapore:
                    <a href="https://youtu.be/rhVhR22t2IE"
                      >Sentiment Analysis, its techniques and applications</a
                    >
                    [June2016]

                </li>
              </ul>
            </div>
          </div>
          <div class="service">
            <h1 class="heading-m" class="py-1">Service</h1>
            <ul>
              <li>Reviewer for ICMI 2018/2019, ACII 2019, ICDMW 2016</li>
            </ul>
          </div>


        <div id="suggestedlinks" class="suggestedlinks">
          <h1 class="heading-m py-1"></h1>
          <h1 class="heading-m py-1">I am really glad I read</h1>
          <ul>
            <li><a href="http://faculty.washington.edu/wobbrock/pubs/Wobbrock-2015.pdf">Catchy Titles Are Good: But Avoid Being Cute</a></li>
            <li><a href="http://approximatelycorrect.com/2018/01/29/heuristics-technical-scientific-writing-machine-learning-perspective/">Heuristics for Scientific Writing (a Machine Learning Perspective)</a></li>
            <li><a href="https://www.csee.umbc.edu/~mariedj/papers/advice.pdf">How to Succeed in Graduate School: A Guide for Students and Advisors</a></li>
            <li><a href="http://martiansideofthemoon.github.io/2018/05/29/grad-resources.html">Grad School Resources</a></li>
            <li><a href="https://acl2017.wordpress.com/2017/02/23/last-minute-reviewing-advice/amp/?__twitter_impression=true">Last minute reviewing advice</a></li>
            <li><a href="https://towardsdatascience.com/how-you-should-read-research-papers-according-to-andrew-ng-stanford-deep-learning-lectures-98ecbd3ccfb3">How You Should Read Research Papers</a></li>
            <li><a href="https://arxiv.org/abs/1807.03341">Troubling Trends in Machine Learning Scholarship</a></li>
          </ul>

        </div>
        </div>
      </div>

      </section>
    </main>
  </body>
  <script src="https://unpkg.com/feather-icons"></script>
  <script src="js/main.js"></script>
</html>
